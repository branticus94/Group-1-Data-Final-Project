{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ea32f58b-a2fa-446f-b895-7cff86882af2",
   "metadata": {},
   "source": [
    "# OFCOM News Consumption Data - Data Extraction and Creation of Data Structure for Final Cleaning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8aae89db-4320-4d9c-b390-292a319a7d47",
   "metadata": {},
   "source": [
    "## 1. Importing the necessary libraries/modules "
   ]
  },
  {
   "cell_type": "code",
   "id": "bd7de51d-fa93-4ec1-b29c-2371e0b1ba58",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-30T05:59:20.162946Z",
     "start_time": "2024-11-30T05:59:19.918722Z"
    }
   },
   "source": [
    "import pandas as pd\n",
    "from functools import reduce\n",
    "from pathlib import Path\n",
    "import time\n",
    "import re"
   ],
   "outputs": [],
   "execution_count": 1
  },
  {
   "cell_type": "markdown",
   "id": "3c3bd5ff-e711-4a2a-9fa9-ec5cdaf2eec9",
   "metadata": {},
   "source": [
    "## 2. Getting a list of paths for the different Excel Spreadsheets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f2da8239-3ed9-4c76-9343-ed38a2edb0fd",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-28T14:13:30.727401Z",
     "start_time": "2024-11-28T14:13:30.724825Z"
    }
   },
   "outputs": [],
   "source": [
    "path_for_ofcom_datasets = '1_raw_databases/ofcom_covid_data_xlsx'\n",
    "\n",
    "directory_path = Path(path_for_ofcom_datasets)\n",
    "\n",
    "file_list = [f.name for f in directory_path.iterdir() if f.is_file()]\n",
    "\n",
    "file_paths = [f'{path_for_ofcom_datasets}/{file}' for file in file_list if file[-4:] == 'xlsx']\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "895a1644-6ec0-4a00-aa66-0799aa279382",
   "metadata": {},
   "source": [
    "### Reviewing the output - this will be useful so that I can use the paths as an iterable to extract and process the data into its final data structure (uncomment to review)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a376e1f5-1c5e-4d65-b303-72d821219541",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-28T14:13:30.867148Z",
     "start_time": "2024-11-28T14:13:30.847849Z"
    }
   },
   "outputs": [],
   "source": [
    "# file_paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7911cf3a-d028-48bb-bf80-f071f4656e54",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-28T14:13:31.215662Z",
     "start_time": "2024-11-28T14:13:31.212387Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "23"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(file_paths)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f726bbfe-836c-4a5a-9e4a-76020476a178",
   "metadata": {},
   "source": [
    "## 3. Reviewing the structure of the Excel spreadsheet - determining sheet names & creating a list of all the questions in the OFCOM survey data\n",
    "\n",
    "### Having reviewed the Excel spreadsheets I am aware the spreadsheets (those of which I have manually reviewed ~ 10) have the same sheet names (INDEX & P1) for each file path I therefore want to confirm this for all 23 sheets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "146a5ed8-1712-40f4-9aef-11f1010625fe",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-28T14:13:32.525088Z",
     "start_time": "2024-11-28T14:13:31.238072Z"
    }
   },
   "outputs": [],
   "source": [
    "sheet_names = []\n",
    "all_questions = []\n",
    "\n",
    "for file_path in file_paths:\n",
    "    sheet_name = set(pd.ExcelFile(file_path, engine='openpyxl').sheet_names)\n",
    "    sheet_names.append(sheet_name)\n",
    "    INDEX = pd.read_excel(file_path, sheet_name=0)\n",
    "    INDEX.dropna(how='all')\n",
    "    INDEX.rename(columns={'Unnamed: 2': 'question'}, inplace=True)\n",
    "    questions = set(INDEX['question'].tolist())\n",
    "    all_questions.append(questions)\n",
    "\n",
    "set_sheet_names = reduce(lambda x, y: x.intersection(y), sheet_names)\n",
    "common_elements = reduce(lambda x, y: x.intersection(y), all_questions)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fbe1537-3cda-466a-b621-13c86d32c181",
   "metadata": {},
   "source": [
    "### Confirming that all the files have sheet Index & P1 and creating a list of the common questions to all 23 spreadsheets and all the questions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f47be27a-dc5f-4055-832d-a91a76685c7d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-28T14:13:32.540301Z",
     "start_time": "2024-11-28T14:13:32.537148Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'INDEX', 'P1'}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set_sheet_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d17e410e-638d-48d0-95fa-8ff3346a6b5d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-28T14:13:32.556195Z",
     "start_time": "2024-11-28T14:13:32.554310Z"
    }
   },
   "outputs": [],
   "source": [
    "list_questions_common_to_all_sheets = list(common_elements)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5798876f-a5c2-4e9b-ae22-49c32c4f07d2",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-28T14:13:32.566119Z",
     "start_time": "2024-11-28T14:13:32.563497Z"
    }
   },
   "outputs": [],
   "source": [
    "all_questions_flattened = set().union(*all_questions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "26df9e5c-4f5f-43e7-a10a-94872b72ad18",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-28T14:13:32.575530Z",
     "start_time": "2024-11-28T14:13:32.573491Z"
    }
   },
   "outputs": [],
   "source": [
    "all_questions_list = list(all_questions_flattened)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b30d7909-e511-4cf5-a215-aa08724761b9",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-28T14:13:32.590913Z",
     "start_time": "2024-11-28T14:13:32.587957Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "234"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(all_questions_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a7a340b-acb1-4ac0-b55e-57a665998701",
   "metadata": {},
   "source": [
    "## 4. Creating a function which takes a dataframe as an argument and returns the date of the survey (for use later so I can combine dataframes for each question and understand the changes over time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "11f4f8bb-a7d6-4e7a-b334-e4290efac9a7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-28T14:13:32.607371Z",
     "start_time": "2024-11-28T14:13:32.604035Z"
    }
   },
   "outputs": [],
   "source": [
    "def determine_date_of_fieldwork(dataframe):\n",
    "    df = dataframe.copy()\n",
    "    \n",
    "    df = df[df.apply(lambda row: row.astype(str).str.contains('ONLINE Fieldwork:', na=False).any(), axis=1)]\n",
    "    \n",
    "    filtered_df = df.loc[:, df.apply(lambda col: col.astype(str).str.contains('ONLINE Fieldwork:', na=False).any(), axis=0)]\n",
    "    \n",
    "    date = filtered_df.iloc[0].tolist()[0]\n",
    "\n",
    "    return date"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "093e6b0a-a5d2-4e7a-a24f-8f71a61c42ef",
   "metadata": {},
   "source": [
    "#### Checking the function works:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "629781e7fa19dbe9",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-28T14:13:32.884243Z",
     "start_time": "2024-11-28T14:13:32.622623Z"
    }
   },
   "outputs": [],
   "source": [
    "file_path = file_paths[0]\n",
    "\n",
    "P1 = pd.read_excel(file_path, sheet_name=1)\n",
    "\n",
    "file_path = file_paths[0]\n",
    "\n",
    "INDEX = pd.read_excel(file_path, sheet_name=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9e9ed26f-67c4-4a5c-9511-2a1b00be5110",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-28T14:13:33.144045Z",
     "start_time": "2024-11-28T14:13:32.894507Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'ONLINE Fieldwork: 9th to 13th April 2020'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "date = determine_date_of_fieldwork(P1)\n",
    "date"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58e5e2e4-3bd6-49ce-951c-60ea20251ad1",
   "metadata": {},
   "source": [
    "## 5. Reviewing one of the sheet dataframes to see what needs to be done with the data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4196b94b-d481-4802-b381-c110f9e0a9f5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-28T14:13:33.171749Z",
     "start_time": "2024-11-28T14:13:33.164Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Return to Index</th>\n",
       "      <th>Unnamed: 2</th>\n",
       "      <th>Unnamed: 3</th>\n",
       "      <th>Unnamed: 4</th>\n",
       "      <th>Unnamed: 5</th>\n",
       "      <th>Unnamed: 6</th>\n",
       "      <th>Unnamed: 7</th>\n",
       "      <th>Unnamed: 8</th>\n",
       "      <th>Unnamed: 9</th>\n",
       "      <th>Unnamed: 10</th>\n",
       "      <th>Unnamed: 11</th>\n",
       "      <th>Unnamed: 12</th>\n",
       "      <th>Unnamed: 13</th>\n",
       "      <th>Unnamed: 14</th>\n",
       "      <th>Unnamed: 15</th>\n",
       "      <th>Unnamed: 16</th>\n",
       "      <th>Unnamed: 17</th>\n",
       "      <th>Unnamed: 18</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Page 1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Ofcom Coronavirus Survey - Week 3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>ONLINE Fieldwork: 9th to 13th April 2020</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Absolutes/col percents</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NaN</td>\n",
       "      <td>Table 1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5269</th>\n",
       "      <td>NaN</td>\n",
       "      <td>Prepared by Populus</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5270</th>\n",
       "      <td>NaN</td>\n",
       "      <td>Note: Sample sizes less than 100 should be tre...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5271</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5272</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5273</th>\n",
       "      <td>NaN</td>\n",
       "      <td>Return to Index</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5274 rows Ã— 19 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Unnamed: 0                                    Return to Index  \\\n",
       "0           NaN                                                NaN   \n",
       "1           NaN                                                NaN   \n",
       "2           NaN                                                NaN   \n",
       "3           NaN                                                NaN   \n",
       "4           NaN                                            Table 1   \n",
       "...         ...                                                ...   \n",
       "5269        NaN                                Prepared by Populus   \n",
       "5270        NaN  Note: Sample sizes less than 100 should be tre...   \n",
       "5271        NaN                                                NaN   \n",
       "5272        NaN                                                NaN   \n",
       "5273        NaN                                    Return to Index   \n",
       "\n",
       "                                    Unnamed: 2 Unnamed: 3 Unnamed: 4  \\\n",
       "0                                          NaN        NaN        NaN   \n",
       "1            Ofcom Coronavirus Survey - Week 3        NaN        NaN   \n",
       "2     ONLINE Fieldwork: 9th to 13th April 2020        NaN        NaN   \n",
       "3                                          NaN        NaN        NaN   \n",
       "4                                          NaN        NaN        NaN   \n",
       "...                                        ...        ...        ...   \n",
       "5269                                       NaN        NaN        NaN   \n",
       "5270                                       NaN        NaN        NaN   \n",
       "5271                                       NaN        NaN        NaN   \n",
       "5272                                       NaN        NaN        NaN   \n",
       "5273                                       NaN        NaN        NaN   \n",
       "\n",
       "     Unnamed: 5 Unnamed: 6 Unnamed: 7 Unnamed: 8 Unnamed: 9 Unnamed: 10  \\\n",
       "0           NaN        NaN        NaN        NaN        NaN         NaN   \n",
       "1           NaN        NaN        NaN        NaN        NaN         NaN   \n",
       "2           NaN        NaN        NaN        NaN        NaN         NaN   \n",
       "3           NaN        NaN        NaN        NaN        NaN         NaN   \n",
       "4           NaN        NaN        NaN        NaN        NaN         NaN   \n",
       "...         ...        ...        ...        ...        ...         ...   \n",
       "5269        NaN        NaN        NaN        NaN        NaN         NaN   \n",
       "5270        NaN        NaN        NaN        NaN        NaN         NaN   \n",
       "5271        NaN        NaN        NaN        NaN        NaN         NaN   \n",
       "5272        NaN        NaN        NaN        NaN        NaN         NaN   \n",
       "5273        NaN        NaN        NaN        NaN        NaN         NaN   \n",
       "\n",
       "     Unnamed: 11 Unnamed: 12 Unnamed: 13 Unnamed: 14 Unnamed: 15 Unnamed: 16  \\\n",
       "0            NaN         NaN         NaN         NaN         NaN         NaN   \n",
       "1            NaN         NaN         NaN         NaN         NaN         NaN   \n",
       "2            NaN         NaN         NaN         NaN         NaN         NaN   \n",
       "3            NaN         NaN         NaN         NaN         NaN         NaN   \n",
       "4            NaN         NaN         NaN         NaN         NaN         NaN   \n",
       "...          ...         ...         ...         ...         ...         ...   \n",
       "5269         NaN         NaN         NaN         NaN         NaN         NaN   \n",
       "5270         NaN         NaN         NaN         NaN         NaN         NaN   \n",
       "5271         NaN         NaN         NaN         NaN         NaN         NaN   \n",
       "5272         NaN         NaN         NaN         NaN         NaN         NaN   \n",
       "5273         NaN         NaN         NaN         NaN         NaN         NaN   \n",
       "\n",
       "     Unnamed: 17             Unnamed: 18  \n",
       "0            NaN                  Page 1  \n",
       "1            NaN                     NaN  \n",
       "2            NaN                     NaN  \n",
       "3            NaN  Absolutes/col percents  \n",
       "4            NaN                     NaN  \n",
       "...          ...                     ...  \n",
       "5269         NaN                     NaN  \n",
       "5270         NaN                     NaN  \n",
       "5271         NaN                     NaN  \n",
       "5272         NaN                     NaN  \n",
       "5273         NaN                     NaN  \n",
       "\n",
       "[5274 rows x 19 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "P1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "855cd474-3c93-4c88-9b18-6a3e5b49fadd",
   "metadata": {},
   "source": [
    "### As you can see from the above dataframe there are lots of redundancies - I need to find and separate the tables for each question!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0135a093-a403-4853-81cf-cb05434a8614",
   "metadata": {},
   "source": [
    "## 6. Splitting the dataframe into individual tables for each question"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef7dd72d-7ecf-4fe6-9f85-9315c2de71a7",
   "metadata": {},
   "source": [
    "### I first look through a row to see if there is a cell which contains the string 'Table' and return the row - this function will be used later"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7a123183-039b-424d-8e0d-11f77abdfd9b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-28T14:13:33.240953Z",
     "start_time": "2024-11-28T14:13:33.239048Z"
    }
   },
   "outputs": [],
   "source": [
    "def is_table_start(row):\n",
    "    return row.str.contains(r\"Table \\d+\", na=False).any()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3892079c-9d7d-4ff7-b083-05bef790e756",
   "metadata": {},
   "source": [
    "### I then generate a list of dataframes for each question for a given spreadsheet, these will need further cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "1c551e3e-66de-4120-98aa-509101063e9f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-28T14:13:33.300982Z",
     "start_time": "2024-11-28T14:13:33.286652Z"
    }
   },
   "outputs": [],
   "source": [
    "def generate_uncleaned_tables(dataframe):\n",
    "    table_start_indices = dataframe.apply(is_table_start, axis=1).index[dataframe.apply(is_table_start, axis=1)].tolist()\n",
    "    table_start_indices.append(len(dataframe))\n",
    "    \n",
    "    tables = []\n",
    "    \n",
    "    for i in range(len(table_start_indices) - 1):\n",
    "        start_idx = table_start_indices[i]\n",
    "        end_idx = table_start_indices[i + 1]\n",
    "        table = dataframe.iloc[start_idx:end_idx].reset_index(drop=True)\n",
    "        tables.append(table)\n",
    "\n",
    "    return tables"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d5daea5-9b14-475a-bc61-425d11c747c6",
   "metadata": {},
   "source": [
    "### The length of this list correlates to the number of tables - this means hopefully each table is within its own dataframe although, it will need processing to extract the data and combine it in a meaningful manner to get insights for a region over time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "9d1e9008-a239-4765-b2cb-45da40e4d7d0",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-28T14:13:33.982666Z",
     "start_time": "2024-11-28T14:13:33.654078Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "122"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "uncleaned_tables = generate_uncleaned_tables(P1)\n",
    "len(uncleaned_tables)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "7a58d2df-5b8c-4bc3-b726-6125ca42ca19",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-28T14:13:34.450974Z",
     "start_time": "2024-11-28T14:13:34.445245Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Ofcom Coronavirus Survey - Week 3</th>\n",
       "      <th>Unnamed: 1</th>\n",
       "      <th>Unnamed: 2</th>\n",
       "      <th>Unnamed: 3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>122</td>\n",
       "      <td>122</td>\n",
       "      <td>122</td>\n",
       "      <td>122</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>122</td>\n",
       "      <td>102</td>\n",
       "      <td>97</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>Page 1</td>\n",
       "      <td>Table 67</td>\n",
       "      <td>Q12. To what extent do you agree or disagree w...</td>\n",
       "      <td>Base: All respondents who are getting informat...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>44</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Ofcom Coronavirus Survey - Week 3 Unnamed: 1  \\\n",
       "count                                122        122   \n",
       "unique                               122        102   \n",
       "top                               Page 1   Table 67   \n",
       "freq                                   1          5   \n",
       "\n",
       "                                               Unnamed: 2  \\\n",
       "count                                                 122   \n",
       "unique                                                 97   \n",
       "top     Q12. To what extent do you agree or disagree w...   \n",
       "freq                                                    6   \n",
       "\n",
       "                                               Unnamed: 3  \n",
       "count                                                 122  \n",
       "unique                                                 14  \n",
       "top     Base: All respondents who are getting informat...  \n",
       "freq                                                   44  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "INDEX.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5aa39da8-ee2a-4f50-b9ae-4c258ebbf5a7",
   "metadata": {},
   "source": [
    "## 7. Cleaning the table"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ee01da1-0e33-406c-b6ec-d1c3318e60bf",
   "metadata": {},
   "source": [
    "## After much manipulation and reviewing of the output I was able to produce a function which processes each unclean table and does an initial clean"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25a79828-ebfe-49cf-9f41-e4f053be23b4",
   "metadata": {},
   "source": [
    "### I first reviewed a dataframe from the initial split for the first question (index 0 in the list) to see what needs to be done and how I can extract the data (uncomment to review)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d3ccaf62-0990-4f4c-822e-aa5e87a66ac7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-28T14:13:34.483372Z",
     "start_time": "2024-11-28T14:13:34.481442Z"
    }
   },
   "outputs": [],
   "source": [
    "# uncleaned_tables[0].head"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "fccc4dac-f82a-49d1-a993-87956488aff3",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-28T14:13:34.527746Z",
     "start_time": "2024-11-28T14:13:34.524224Z"
    }
   },
   "outputs": [],
   "source": [
    "def first_clean_dataframe(i, dataframe, date):\n",
    "    try:         \n",
    "        dataframe.drop(columns=dataframe.columns[dataframe.isin(['@removesigrow@']).any()], inplace=True)\n",
    "        \n",
    "        dataframe = dataframe.rename(columns = {'Return to Index': 'response'})\n",
    "        \n",
    "        table = dataframe['response'].iloc[0]\n",
    "        question = dataframe['response'].iloc[1]\n",
    "        \n",
    "        alternate_left_column_of_data = dataframe['Unnamed: 3']\n",
    "        \n",
    "        alternate_left_top_corner = alternate_left_column_of_data.first_valid_index()\n",
    "\n",
    "        # print(\"alternate_left_top_corner:\", alternate_left_top_corner)\n",
    "        \n",
    "        left_column_of_data = dataframe['Unnamed: 2']\n",
    "        \n",
    "        left_column_of_data = left_column_of_data[~left_column_of_data.str.contains('Ofcom Coronavirus Survey|ONLINE Fieldwork', case=False, na=False)]\n",
    "        \n",
    "        left_top_corner = left_column_of_data.first_valid_index()\n",
    "\n",
    "        # print(\"left_top_corner:\", left_top_corner)\n",
    "        \n",
    "        left_bottom_corner = left_column_of_data[::-1].first_valid_index()\n",
    "\n",
    "        # print(\"left_bottom_corner:\", left_bottom_corner)\n",
    "\n",
    "        def first_valid_index_from_right(row):\n",
    "            valid_indices = row.notna()[::-1]\n",
    "            index = valid_indices.idxmax() if valid_indices.any() else None\n",
    "            return index\n",
    "        \n",
    "        if alternate_left_top_corner > left_top_corner:\n",
    "            left_top_corner=alternate_left_top_corner\n",
    "        \n",
    "        # print(\"final left_top_corner:\", left_top_corner)\n",
    "\n",
    "        row = dataframe.iloc[left_top_corner]\n",
    "        \n",
    "        right_top_corner = dataframe.columns.get_loc(first_valid_index_from_right(row)) + 1\n",
    "        # print(\"right_top_corner:\", right_top_corner)\n",
    "\n",
    "        sliced_dataframe = dataframe.iloc[left_top_corner:left_bottom_corner, :right_top_corner]\n",
    "\n",
    "        sliced_dataframe.columns = sliced_dataframe.iloc[0]\n",
    "\n",
    "        sliced_dataframe = sliced_dataframe.dropna(axis=1, how='all')\n",
    "\n",
    "        sliced_dataframe.rename(columns={ sliced_dataframe.columns[0]: \"response\" }, inplace = True)\n",
    "        \n",
    "        sliced_dataframe = sliced_dataframe.dropna(subset=[\"response\"])\n",
    "        \n",
    "        sliced_dataframe = sliced_dataframe[sliced_dataframe['response'] != ' ']\n",
    "        \n",
    "        if sliced_dataframe.empty:\n",
    "            return i\n",
    "\n",
    "        sliced_dataframe.insert(0, 'date', date)\n",
    "        sliced_dataframe.insert(0, 'question', question)\n",
    "        sliced_dataframe.insert(0, 'table', table)\n",
    "        \n",
    "        return sliced_dataframe, question\n",
    "    except:\n",
    "        print(f\"Error in first_clean_dataframe {date}. Table: {i}\")\n",
    "        return f\"Error in first_clean_dataframe {date}. Table: {i}\", f\"Error in first_clean_dataframe {date}. Table: {i}\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc17725f-75fc-4ebe-8f66-46e8107ad942",
   "metadata": {},
   "source": [
    "## 8. Testing the cleaning function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "f20f28d9-7b1d-4755-966c-937ed14c4f76",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-28T14:13:34.570446Z",
     "start_time": "2024-11-28T14:13:34.563050Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5     table                                 question  \\\n",
       " 6   Table 1  Q1. Device usage to connect to internet   \n",
       " 7   Table 1  Q1. Device usage to connect to internet   \n",
       " 8   Table 1  Q1. Device usage to connect to internet   \n",
       " 11  Table 1  Q1. Device usage to connect to internet   \n",
       " 15  Table 1  Q1. Device usage to connect to internet   \n",
       " 19  Table 1  Q1. Device usage to connect to internet   \n",
       " 22  Table 1  Q1. Device usage to connect to internet   \n",
       " 25  Table 1  Q1. Device usage to connect to internet   \n",
       " 29  Table 1  Q1. Device usage to connect to internet   \n",
       " 33  Table 1  Q1. Device usage to connect to internet   \n",
       " 37  Table 1  Q1. Device usage to connect to internet   \n",
       " 40  Table 1  Q1. Device usage to connect to internet   \n",
       " \n",
       " 5                                       date  \\\n",
       " 6   ONLINE Fieldwork: 9th to 13th April 2020   \n",
       " 7   ONLINE Fieldwork: 9th to 13th April 2020   \n",
       " 8   ONLINE Fieldwork: 9th to 13th April 2020   \n",
       " 11  ONLINE Fieldwork: 9th to 13th April 2020   \n",
       " 15  ONLINE Fieldwork: 9th to 13th April 2020   \n",
       " 19  ONLINE Fieldwork: 9th to 13th April 2020   \n",
       " 22  ONLINE Fieldwork: 9th to 13th April 2020   \n",
       " 25  ONLINE Fieldwork: 9th to 13th April 2020   \n",
       " 29  ONLINE Fieldwork: 9th to 13th April 2020   \n",
       " 33  ONLINE Fieldwork: 9th to 13th April 2020   \n",
       " 37  ONLINE Fieldwork: 9th to 13th April 2020   \n",
       " 40  ONLINE Fieldwork: 9th to 13th April 2020   \n",
       " \n",
       " 5                                            response Total (a) Male (b)  \\\n",
       " 6                                     Unweighted base      2127     1021   \n",
       " 7                                       Weighted base      2127     1040   \n",
       " 8             NET: Used device to connect to internet      2116     1032   \n",
       " 11                                         Smartphone      1693      844   \n",
       " 15                                             Laptop      1386      691   \n",
       " 19                        Tablet computer (e.g. iPad)      1015      483   \n",
       " 22                                             TV set       923      467   \n",
       " 25                                         Desktop PC       701      430   \n",
       " 29                                      Games console       403      246   \n",
       " 33      Smart speaker (e.g. Amazon Echo, Google Home)       400      217   \n",
       " 37                             E-reader (e.g. Kindle)       195       72   \n",
       " 40  Smart watch (e.g. Apple Watch, Pebble, Samsung...       143       85   \n",
       " \n",
       " 5  Female (c) 16-24 (d) 18-24 (e) 25-34 (f) 35-44 (g) 45-54 (h) 55-64 (i)  \\\n",
       " 6        1106       267       236       343       347       383       319   \n",
       " 7        1087       294       258       355       329       366       306   \n",
       " 8        1084       292       256       351       326       363       306   \n",
       " 11        848       267       234       327       299       297       226   \n",
       " 15        695       222       196       245       224       242       190   \n",
       " 19        532       102        83       169       172       175       144   \n",
       " 22        457       129       106       176       160       159       120   \n",
       " 25        272        86        80        85        92       121       105   \n",
       " 29        157       111        95       108        94        67        14   \n",
       " 33        183        51        46        99        81        75        41   \n",
       " 37        123        24        24        41        32        33        18   \n",
       " 40         58        28        26        40        38        16         8   \n",
       " \n",
       " 5  65+ (j) AB (k) C1 (l) C2 (m) DE (n)  \n",
       " 6      468    606    513    453    555  \n",
       " 7      477    578    600    432    517  \n",
       " 8      477    574    599    430    514  \n",
       " 11     276    486    479    347    380  \n",
       " 15     263    422    395    268    302  \n",
       " 19     252    289    275    213    238  \n",
       " 22     179    256    256    214    197  \n",
       " 25     212    211    202    135    153  \n",
       " 29       9    115    108     83     97  \n",
       " 33      54    135    102     92     72  \n",
       " 37      46     55     56     36     48  \n",
       " 40      13     53     27     37     27  ,\n",
       " 'Q1. Device usage to connect to internet')"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_dataframe = first_clean_dataframe(0, uncleaned_tables[0], date)\n",
    "test_dataframe"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9192827-d755-405c-b296-b45a65288e84",
   "metadata": {},
   "source": [
    "### As you can see the cleaning function seems to have created a dataframe which is perfect for further cleaning/manipulation & visualisation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6efa8cc0-9457-4fec-a142-cb9ac55c252e",
   "metadata": {},
   "source": [
    "## 8.Using the splitting and cleaning functions for all spreadsheets to obtain all the data\n",
    " \n",
    "### I now want to iterate over all the file paths, split the table for that file into dataframes for individual questions and perform an initial clean on the individual dataframes - this then needs to be stored in a data-structure which will be further processed so that the results of a single dataframe show the results for each question over time"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf70404c-32ee-4fac-845b-54f5f30d72bc",
   "metadata": {},
   "source": [
    "### I now want to iterate over all the file paths, split the table for that file into dataframes for individual questions and perform an initial clean on the individual dataframes - this then needs to be stored in a data-structure which will be further processed so that the results of a single dataframe show the results for each question over time"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "362a8bc8-550d-4944-8425-6bec40535417",
   "metadata": {},
   "source": [
    "### Getting a list of dataframes for each Excel file\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "40590a79-a331-4786-bef2-10fffe392dbb",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-28T14:13:45.725558Z",
     "start_time": "2024-11-28T14:13:35.032201Z"
    }
   },
   "outputs": [],
   "source": [
    "initial_dataframes_from_file_path = []\n",
    "\n",
    "for file_path in file_paths:\n",
    "    dataframe = pd.read_excel(file_path, sheet_name=1)\n",
    "    initial_dataframes_from_file_path.append(dataframe)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d20e17b9-0729-445e-b485-dec8ee52f266",
   "metadata": {},
   "source": [
    "### Determining the dates for each file and saving their value in a list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "c3edecc7-7aa2-4706-8e04-780a8c46aca5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-28T14:13:54.416530Z",
     "start_time": "2024-11-28T14:13:45.739391Z"
    }
   },
   "outputs": [],
   "source": [
    "dates = []\n",
    "\n",
    "for dataframe in initial_dataframes_from_file_path:\n",
    "    dates.append(determine_date_of_fieldwork(dataframe))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25557852-1ed8-45c1-99a0-ec4fec190039",
   "metadata": {},
   "source": [
    "### Creating an empty data structure of a dictionary of lists which will contain the dataframe relating to each question\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "fa1d05dc-35e2-43c6-891d-128a1cd23b3a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-28T14:13:54.433028Z",
     "start_time": "2024-11-28T14:13:54.431308Z"
    }
   },
   "outputs": [],
   "source": [
    "cleaned_tables = {question: [] for question in all_questions_list}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "c539cbd3-fd83-41fa-8ea8-750de50cca17",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-28T14:14:09.535080Z",
     "start_time": "2024-11-28T14:13:54.447203Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error in first_clean_dataframe ONLINE Fieldwork: 4th to 6th December 2020. Table: 17\n"
     ]
    }
   ],
   "source": [
    "tables_split_and_cleaned = 0\n",
    "\n",
    "for i, initial_dataframe in enumerate(initial_dataframes_from_file_path):\n",
    "    \n",
    "    uncleaned_dataframe_for_question = generate_uncleaned_tables(initial_dataframe)\n",
    "\n",
    "    date = dates[i]\n",
    "\n",
    "    failed_tables = []\n",
    "\n",
    "    uncategorized_tables = []\n",
    "    \n",
    "    for uncleaned_dataframe in uncleaned_dataframe_for_question:\n",
    "        initial_clean_dataframe, question = first_clean_dataframe(i, uncleaned_dataframe, date)\n",
    "        tables_split_and_cleaned += 1\n",
    "        if initial_clean_dataframe is str:\n",
    "            failed_tables.append(f\"Failed to process Survey date:{date} dataframe: {i}, Question: {question}\")\n",
    "        else:\n",
    "            if question in cleaned_tables.keys():\n",
    "                cleaned_tables[question].append(initial_clean_dataframe)\n",
    "            else:\n",
    "                uncategorized_tables.append(initial_clean_dataframe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "9331eb40cf0f85bb",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-28T14:14:09.559740Z",
     "start_time": "2024-11-28T14:14:09.557603Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4232"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tables_split_and_cleaned"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e43d6d6-8d29-46dc-a16b-bf0a5e9b0556",
   "metadata": {},
   "source": [
    "### The operation was a success for all but one table - this would be sufficient to look at manually if felt necessary!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc1dce51-1c45-43da-a06d-e8422b244474",
   "metadata": {},
   "source": [
    "### There are roughly 200 questions in each spreadsheet and 23 spreadsheets therefore the 4232 tables seems appropriate for the task at hand"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a47569e-8e29-4e1d-922f-171fbfa1ee66",
   "metadata": {},
   "source": [
    "## 9. Combining the dataframes within a question"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "613ef372c813336d",
   "metadata": {},
   "source": [
    "### I first test my code on the first question"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "c687429c-b62f-4d88-af2a-64f0c3533035",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-28T14:14:09.583919Z",
     "start_time": "2024-11-28T14:14:09.581686Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Q5. Trust in the sources for information/news about Coronavirus used in last week: Websites/apps of online news organisations like Buzzfeed, Huffington Post, Vice, etc.'"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "question = list_questions_common_to_all_sheets[0]\n",
    "question"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6d0418e-4f61-4154-940b-41727db14783",
   "metadata": {},
   "source": [
    "#### I had a look at all the dataframes within a list for that question to determine which logic I should use - after playing around with different parameters it seems that some columns are present at certain times and not at others so, I will need to produce a list of columns from all the dataframes, create an empty dataframe with those column names and the add each dataframe to the master dataframe, filling in gaps with Nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "3b3fe72a-71cc-4d21-9e58-fc0fad7daebc",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-28T14:58:09.913095Z",
     "start_time": "2024-11-28T14:58:09.910106Z"
    }
   },
   "outputs": [],
   "source": [
    "def collect_columns_in_order(list_dataframes):\n",
    "    all_columns = []\n",
    "    for dataframe in list_dataframes:\n",
    "        for column in dataframe.columns:\n",
    "            if column not in all_columns:\n",
    "                all_columns.append(column)\n",
    "    return all_columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "d55ce91dbbbcc9d0",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-28T14:58:10.782598Z",
     "start_time": "2024-11-28T14:58:10.780234Z"
    }
   },
   "outputs": [],
   "source": [
    "def rename_duplicate_columns(columns):\n",
    "    seen = {}\n",
    "    new_columns = []\n",
    "    \n",
    "    for col in columns:\n",
    "        if col in seen:\n",
    "            seen[col] += 1\n",
    "            new_columns.append(f\"{col}_{seen[col]}\")  # Rename with suffix\n",
    "        else:\n",
    "            seen[col] = 0\n",
    "            new_columns.append(col)\n",
    "    \n",
    "    return new_columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "d20caba5-58f6-400b-aa91-2cd665a54d9f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-28T14:58:11.230766Z",
     "start_time": "2024-11-28T14:58:11.228257Z"
    }
   },
   "outputs": [],
   "source": [
    "def combine_dataframes(list_dataframes):\n",
    "    all_columns = collect_columns_in_order(list_dataframes)\n",
    "    \n",
    "    combined_df = pd.DataFrame(columns=all_columns)\n",
    "    \n",
    "    for dataframe in list_dataframes:\n",
    "        dataframe.columns = rename_duplicate_columns(dataframe.columns)\n",
    "        \n",
    "        dataframe = dataframe.reindex(columns=all_columns, fill_value=None)\n",
    "        \n",
    "        combined_df = pd.concat([combined_df, dataframe], ignore_index=True)\n",
    "\n",
    "    return combined_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "f8b398fcbd00fb43",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-28T14:58:15.715299Z",
     "start_time": "2024-11-28T14:58:12.113239Z"
    }
   },
   "outputs": [],
   "source": [
    "for question in list_questions_common_to_all_sheets:\n",
    "    combined_dataframe = combine_dataframes(cleaned_tables[question])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "f7d1fe427de81699",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-28T14:16:16.252747Z",
     "start_time": "2024-11-28T14:14:12.495721Z"
    }
   },
   "outputs": [],
   "source": [
    "cleaned_combined_tables = {question: [] for question in all_questions_list}\n",
    "\n",
    "for key in cleaned_combined_tables.keys():\n",
    "    cleaned_combined_tables[key] = combine_dataframes(cleaned_tables[key])\n",
    "    time.sleep(0.5)"
   ]
  },
  {
   "cell_type": "code",
   "id": "9707dc646e60e88e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-28T15:19:36.870595Z",
     "start_time": "2024-11-28T15:19:36.843697Z"
    }
   },
   "source": [
    "for key in cleaned_combined_tables.keys():\n",
    "    cleaned_key = re.sub(r'[^\\w\\s]', '', str(key))\n",
    "    cleaned_key = cleaned_key.lower().replace(\" \",\"_\")\n",
    "    cleaned_combined_tables[key].to_csv(f\"2_processed_databases/ofcom_data/{cleaned_key}.csv\", index=False)"
   ],
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'cleaned_combined_tables' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[3], line 1\u001B[0m\n\u001B[0;32m----> 1\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m key \u001B[38;5;129;01min\u001B[39;00m \u001B[43mcleaned_combined_tables\u001B[49m\u001B[38;5;241m.\u001B[39mkeys():\n\u001B[1;32m      2\u001B[0m     cleaned_key \u001B[38;5;241m=\u001B[39m re\u001B[38;5;241m.\u001B[39msub(\u001B[38;5;124mr\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m[^\u001B[39m\u001B[38;5;124m\\\u001B[39m\u001B[38;5;124mw\u001B[39m\u001B[38;5;124m\\\u001B[39m\u001B[38;5;124ms]\u001B[39m\u001B[38;5;124m'\u001B[39m, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124m'\u001B[39m, \u001B[38;5;28mstr\u001B[39m(key))\n\u001B[1;32m      3\u001B[0m     cleaned_key \u001B[38;5;241m=\u001B[39m cleaned_key\u001B[38;5;241m.\u001B[39mlower()\u001B[38;5;241m.\u001B[39mreplace(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m \u001B[39m\u001B[38;5;124m\"\u001B[39m,\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m_\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n",
      "\u001B[0;31mNameError\u001B[0m: name 'cleaned_combined_tables' is not defined"
     ]
    }
   ],
   "execution_count": 3
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a2e94c0a947da42",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
